{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo-Itum67DFe"
      },
      "source": [
        "# Immporte das bibliotecas e constantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czze3ixPcV_f",
        "outputId": "68f1290c-5f81-4614-d725-930f04cecc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mplhep in /root/.local/lib/python3.7/site-packages (0.3.26)\n",
            "Requirement already satisfied: matplotlib>=3.4 in /root/.local/lib/python3.7/site-packages (from mplhep) (3.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from mplhep) (1.21.6)\n",
            "Requirement already satisfied: uhi>=0.2.0 in /root/.local/lib/python3.7/site-packages (from mplhep) (0.3.1)\n",
            "Requirement already satisfied: mplhep-data in /root/.local/lib/python3.7/site-packages (from mplhep) (0.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mplhep) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->mplhep) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->mplhep) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /root/.local/lib/python3.7/site-packages (from matplotlib>=3.4->mplhep) (4.37.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->mplhep) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->mplhep) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->mplhep) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.4->mplhep) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->mplhep) (1.15.0)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install --user mplhep\n",
        "import mplhep as hep \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from joblib import load\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Amostras_4Anomalos_Macedo/'\n",
        "PATH_ = '/content/drive/MyDrive/Amostras_4Anomalos_Macedo_Eventos/'\n",
        "PATH2 = '/content/drive/MyDrive/LGBM_Multiclass_ANOMALO_WWCEP_ Drecision_Tree/'\n",
        "raiz_s = 13000\n",
        "plt.style.use([hep.style.ROOT, hep.style.firamath])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH3jahOi7A7A"
      },
      "source": [
        "# Abrindo os arquivos .h5\n",
        "- Aplicando o corte na região de controle do Signal\n",
        "- Corrigindo as colunas do Background\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doe_NG2Mc5XX"
      },
      "outputs": [],
      "source": [
        "# Corte na região de sinal e adicionado corte na Massa Invariante do W\n",
        "\n",
        "def open_file_back( file ):\n",
        "    df = None\n",
        "    with h5py.File( file , 'r' ) as f:\n",
        "        dset_columns = f['columns']\n",
        "        dset_dados = f['dados']\n",
        "        #print( '\\n colunas --> ', np.array( dset_columns ),'\\n' )\n",
        "        df = pd.DataFrame( np.array(dset_dados), columns = np.array( dset_columns))\n",
        "        df[b'Mpps'] = raiz_s * ( np.sqrt( df[b'xi1'] * df[b'xi2'] ) )\n",
        "        df[b'Ypps'] = 1/2 * np.log( df[b'xi1'] / df[b'xi2'] )\n",
        "        df[b'Mww/Mpps'] = df[b'W_Mass'] / df[b'Mpps']\n",
        "        df[b'Ypps-Yww'] = df[b'Ypps'] - df[b'W_rapidity']\n",
        "        df[b'label'] = 0\n",
        "\n",
        "        #df_cut = (df[b'muon_pt'] > 53)  & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'btag'] == 0) &  (df[b'xi1'] > 0.04) & (df[b'xi2'] > 0.04) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138)   & (df[b'jetAK8_prunedMass'] > 65) & (df[b'jetAK8_prunedMass'] < 105)  &  (df[b'jet_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "        df_cut = (df[b'muon_pt'] > 53) & (df[b'xi1'] > 0.04) & (df[b'W_Mass'] > 600) & (df[b'xi2'] > 0.04) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138) & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'jet_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "\n",
        "        dset = df[df_cut]\n",
        "        return dset\n",
        "\n",
        "\n",
        "def open_file_dados( file ):\n",
        "    df = None\n",
        "    with h5py.File( file , 'r' ) as f:\n",
        "        dset_columns = f['columns']\n",
        "        dset_dados = f['dados']\n",
        "        #print( '\\n colunas --> ', np.array( dset_columns ),'\\n' )\n",
        "        df = pd.DataFrame( np.array(dset_dados), columns = np.array( dset_columns))\n",
        "        df[b'Mpps'] = raiz_s * ( np.sqrt( df[b'xi1'] * df[b'xi2'] ) )\n",
        "        df[b'Ypps'] = 1/2 * np.log( df[b'xi1'] / df[b'xi2'] )\n",
        "        df[b'Mww/Mpps'] = df[b'W_Mass'] / df[b'Mpps']\n",
        "        df[b'Ypps-Yww'] = df[b'Ypps'] - df[b'W_rapidity']\n",
        "\n",
        "        #df_cut = (df[b'muon_pt'] > 53)  & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'btag'] == 0) &  (df[b'xi1'] > 0.04) & (df[b'xi2'] > 0.04) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138)   & (df[b'jetAK8_prunedMass'] > 65) & (df[b'jetAK8_prunedMass'] < 105)  &  (df[b'jet_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "        df_cut = (df[b'muon_pt'] > 53) & (df[b'xi1'] > 0.04) & (df[b'xi2'] > 0.04) & (df[b'W_Mass'] > 600) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138) & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'jet_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "        dset = df[df_cut]\n",
        "        return dset\n",
        "\n",
        "\n",
        "\n",
        "def open_file_signal( file ):\n",
        "    df = None\n",
        "    with h5py.File( file , 'r' ) as f:\n",
        "        dset_columns = f['columns']\n",
        "        dset_dados = f['dados']\n",
        "        #print( '\\n colunas --> ', np.array( dset_columns ),'\\n' )\n",
        "        df = pd.DataFrame( np.array(dset_dados), columns = np.array( dset_columns))\n",
        "        df[b'Mpps'] = raiz_s * ( np.sqrt( df[b'xi1'] * df[b'xi2'] ) )\n",
        "        df[b'Ypps'] = 1/2 * np.log( df[b'xi1'] / df[b'xi2'] )\n",
        "        df[b'Mww/Mpps'] = df[b'W_Mass'] / df[b'Mpps']\n",
        "        df[b'Ypps-Yww'] = df[b'Ypps'] - df[b'W_rapidity']\n",
        "        df[b'label'] = 1\n",
        "\n",
        "        #df_cut = (df[b'muon_pt'] > 53)  & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'btag'] == 0) &  (df[b'xi1'] > 0.04) & (df[b'xi2'] > 0.04) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138)   & (df[b'jetAK8_prunedMass'] > 65) & (df[b'jetAK8_prunedMass'] < 105)  &  (df[b'jetAK8_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "        df_cut = (df[b'muon_pt'] > 53) & (df[b'xi1'] > 0.04) & (df[b'xi2'] > 0.04) & (df[b'W_Mass'] > 600) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138) & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'jetAK8_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "        dset = df[df_cut]\n",
        "        return dset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def open_file_SM( file ):\n",
        "    df = None\n",
        "    with h5py.File( file , 'r' ) as f:\n",
        "        dset_columns = f['columns']\n",
        "        dset_dados = f['dados']\n",
        "        #print( '\\n colunas --> ', np.array( dset_columns ),'\\n' )\n",
        "        df = pd.DataFrame( np.array(dset_dados), columns = np.array( dset_columns))\n",
        "        df[b'Mpps'] = raiz_s * ( np.sqrt( df[b'xi1'] * df[b'xi2'] ) )\n",
        "        df[b'Ypps'] = 1/2 * np.log( df[b'xi1'] / df[b'xi2'] )\n",
        "        df[b'Mww/Mpps'] = df[b'W_Mass'] / df[b'Mpps']\n",
        "        df[b'Ypps-Yww'] = df[b'Ypps'] - df[b'W_rapidity']\n",
        "        df[b'label'] = 2\n",
        "\n",
        "        #df_cut = (df[b'muon_pt'] > 53)  & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'btag'] == 0) &  (df[b'xi1'] > 0.04) & (df[b'xi2'] > 0.04) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138)   & (df[b'jetAK8_prunedMass'] > 65) & (df[b'jetAK8_prunedMass'] < 105)  &  (df[b'jetAK8_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "        df_cut = (df[b'muon_pt'] > 53) & (df[b'xi1'] > 0.04) & (df[b'xi2'] > 0.04) & (df[b'W_Mass'] > 600) & (df[b'xi1'] < 0.111) & (df[b'xi2'] < 0.138) & (df[b'muon_eta'] < 2.4) & (df[b'jetAK8_pt'] > 200) & (df[b'jetAK8_eta'] < 2.4) & (df[b'METPt'] > 40) & (df[b'W_pt_lep'] > 200)\n",
        "        dset = df[df_cut]\n",
        "        return dset\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2FGcZrHc7bf"
      },
      "outputs": [],
      "source": [
        "Drell_Yan = open_file_back(PATH_ + 'DataSet_multiRP_DrellYan.h5')\n",
        "QCD = open_file_back(PATH_ + 'DataSet_multiRP_QCD.h5')\n",
        "Single_top = open_file_back(PATH_ + 'DataSet_multiRP_single_top.h5')\n",
        "VV_Inclusivo = open_file_back(PATH_ + 'DataSet_multiRP_VV_inclusivo.h5')\n",
        "W_Jets = open_file_back(PATH_ + 'DataSet_multiRP_WJets.h5')\n",
        "TT_bar = open_file_back(PATH_ + 'DataSet_TTbar.h5')\n",
        "\n",
        "data = open_file_dados(PATH_ + 'DataSet_dados_multiRP.h5')\n",
        "\n",
        "A01 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO1_multiRP.h5' )\n",
        "A02 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO2_multiRP.h5' )\n",
        "A03 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO3_multiRP.h5' )\n",
        "A04 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO4_multiRP.h5' )\n",
        "A05 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO5_multiRP.h5' )\n",
        "A06 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO6_multiRP.h5' )\n",
        "A07 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO7_multiRP.h5' )\n",
        "A08 = open_file_signal( PATH_ + 'output-DataSet_ANOMALO8_multiRP.h5' )\n",
        "\n",
        "SM = open_file_SM( PATH_ + 'output-SM_multiRP.h5' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNiBnIb1c_L-"
      },
      "outputs": [],
      "source": [
        "columns_ = [ b'W_Mass', b'W_pt_lep', b'dPhi_Whad_Wlep',b'dPhi_jatos_MET', b'jetAK8_pt', b'jetAK8_eta',\n",
        "                b'jetAK8_prunedMass',      b'jetAK8_tau21',             b'METPt',\n",
        "                b'muon_pt',          b'muon_eta',       b'ExtraTracks',\n",
        "               b'PUWeight',        b'W_rapidity',              b'btag',\n",
        "                b'xi1',               b'xi2',b'ismultirp1',        b'ismultirp2',\n",
        "                b'Norm',\n",
        "                  b'weight',              b'Mpps',              b'Ypps',\n",
        "                b'Mww/Mpps',          b'Ypps-Yww', b'label']\n",
        "\n",
        "\n",
        "columns_data = [ b'W_Mass', b'W_pt_lep', b'dPhi_Whad_Wlep',b'dPhi_jatos_MET', b'jetAK8_pt', b'jetAK8_eta',\n",
        "                b'jetAK8_prunedMass',      b'jetAK8_tau21',             b'METPt',\n",
        "                b'muon_pt',          b'muon_eta',       b'ExtraTracks',\n",
        "               b'PUWeight',        b'W_rapidity',              b'btag',\n",
        "                b'xi1',               b'xi2',b'ismultirp1',        b'ismultirp2',\n",
        "                              b'Mpps',              b'Ypps',\n",
        "                b'Mww/Mpps',          b'Ypps-Yww']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DrellYan = pd.DataFrame( np.array(Drell_Yan),columns=columns_ )\n",
        "QCD_ = pd.DataFrame( np.array(QCD),columns=columns_ )\n",
        "SingleTop = pd.DataFrame( np.array(Single_top),columns=columns_ )\n",
        "VVInclusivo = pd.DataFrame( np.array(VV_Inclusivo),columns=columns_ )\n",
        "Wjets = pd.DataFrame( np.array(W_Jets),columns=columns_ )\n",
        "TTbar = pd.DataFrame( np.array(TT_bar),columns=columns_ )\n",
        "\n",
        "data_set_dados_multirp = pd.DataFrame( np.array(data),columns=columns_data )\n",
        "\n",
        "concat_back = pd.concat([DrellYan, QCD_, SingleTop, VVInclusivo, Wjets, TTbar])\n",
        "\n",
        "concat_back[b'label'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA-FOF2j70O4"
      },
      "source": [
        "# Preparando dados de teste e treino da Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJnRgr_ddAuH"
      },
      "outputs": [],
      "source": [
        "DataSet_ANML01 = pd.concat([A01, concat_back, SM])\n",
        "DataSet_ANML02 = pd.concat([A02, concat_back, SM])\n",
        "DataSet_ANML03 = pd.concat([A03, concat_back, SM])\n",
        "DataSet_ANML04 = pd.concat([A04, concat_back, SM])\n",
        "DataSet_ANML05 = pd.concat([A05, concat_back, SM])\n",
        "DataSet_ANML06 = pd.concat([A06, concat_back, SM])\n",
        "DataSet_ANML07 = pd.concat([A07, concat_back, SM])\n",
        "DataSet_ANML08 = pd.concat([A08, concat_back, SM])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHhje3lhdCS6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size_ = 0.5\n",
        "\n",
        "DataSet_Train1_, DataSet_Test1_ = train_test_split( DataSet_ANML01, test_size = test_size_, random_state=42, stratify=DataSet_ANML01[b'label'] )\n",
        "DataSet_Train2_, DataSet_Test2_ = train_test_split( DataSet_ANML02, test_size = test_size_, random_state=42, stratify=DataSet_ANML02[b'label'] )\n",
        "DataSet_Train3_, DataSet_Test3_ = train_test_split( DataSet_ANML03, test_size = test_size_, random_state=42, stratify=DataSet_ANML03[b'label'] )\n",
        "DataSet_Train4_, DataSet_Test4_ = train_test_split( DataSet_ANML04, test_size = test_size_, random_state=42, stratify=DataSet_ANML04[b'label'] )\n",
        "DataSet_Train5_, DataSet_Test5_ = train_test_split( DataSet_ANML05, test_size = test_size_, random_state=42, stratify=DataSet_ANML05[b'label'] )\n",
        "DataSet_Train6_, DataSet_Test6_ = train_test_split( DataSet_ANML06, test_size = test_size_, random_state=42, stratify=DataSet_ANML06[b'label'] )\n",
        "DataSet_Train7_, DataSet_Test7_ = train_test_split( DataSet_ANML07, test_size = test_size_, random_state=42, stratify=DataSet_ANML07[b'label'] )\n",
        "DataSet_Train8_, DataSet_Test8_ = train_test_split( DataSet_ANML08, test_size = test_size_, random_state=42, stratify=DataSet_ANML08[b'label'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNK1O5fLdjHV"
      },
      "outputs": [],
      "source": [
        "label_train_ANML1 = DataSet_Train1_[b'label']\n",
        "label_test_ANML1 = DataSet_Test1_[b'label']\n",
        "\n",
        "label_train_ANML2 = DataSet_Train2_[b'label']\n",
        "label_test_ANML2 = DataSet_Test2_[b'label']\n",
        "\n",
        "label_train_ANML3 = DataSet_Train3_[b'label']\n",
        "label_test_ANML3 = DataSet_Test3_[b'label']\n",
        "\n",
        "label_train_ANML4 = DataSet_Train4_[b'label']\n",
        "label_test_ANML4 = DataSet_Test4_[b'label']\n",
        "\n",
        "label_train_ANML5 = DataSet_Train5_[b'label']\n",
        "label_test_ANML5 = DataSet_Test5_[b'label']\n",
        "\n",
        "label_train_ANML6 = DataSet_Train6_[b'label']\n",
        "label_test_ANML6 = DataSet_Test6_[b'label']\n",
        "\n",
        "label_train_ANML7 = DataSet_Train7_[b'label']\n",
        "label_test_ANML7 = DataSet_Test7_[b'label']\n",
        "\n",
        "label_train_ANML8 = DataSet_Train8_[b'label']\n",
        "label_test_ANML8 = DataSet_Test8_[b'label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGE4rCZWdjCQ"
      },
      "outputs": [],
      "source": [
        "colunas = [b'W_Mass', b'W_pt_lep', b'dPhi_Whad_Wlep', b'dPhi_jatos_MET', b'jetAK8_pt', b'jetAK8_eta', b'jetAK8_prunedMass', b'jetAK8_tau21', b'METPt', b'muon_pt', b'muon_eta', b'ExtraTracks', b'W_rapidity', b'xi1', b'xi2',b'Mpps', b'Ypps', b'Mww/Mpps', b'Ypps-Yww']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEJilJRPdk0n"
      },
      "outputs": [],
      "source": [
        "DataSet_Train1 = DataSet_Train1_[colunas]\n",
        "DataSet_Test1 = DataSet_Test1_[colunas]\n",
        "\n",
        "DataSet_Train2 = DataSet_Train2_[colunas]\n",
        "DataSet_Test2 = DataSet_Test2_[colunas]\n",
        "\n",
        "DataSet_Train3 = DataSet_Train3_[colunas]\n",
        "DataSet_Test3 = DataSet_Test3_[colunas]\n",
        "\n",
        "DataSet_Train4 = DataSet_Train4_[colunas]\n",
        "DataSet_Test4 = DataSet_Test4_[colunas]\n",
        "\n",
        "DataSet_Train5 = DataSet_Train5_[colunas]\n",
        "DataSet_Test5 = DataSet_Test5_[colunas]\n",
        "\n",
        "DataSet_Train6 = DataSet_Train6_[colunas]\n",
        "DataSet_Test6 = DataSet_Test6_[colunas]\n",
        "\n",
        "DataSet_Train7 = DataSet_Train7_[colunas]\n",
        "DataSet_Test7 = DataSet_Test7_[colunas]\n",
        "\n",
        "DataSet_Train8 = DataSet_Train8_[colunas]\n",
        "DataSet_Test8 = DataSet_Test8_[colunas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8NF0ZtkdtqJ"
      },
      "outputs": [],
      "source": [
        "DataSet_Test1_weight_backg = DataSet_Test1_[DataSet_Test1_[ b'label']==0][b'weight']\n",
        "DataSet_Test1_weight_signal = DataSet_Test1_[DataSet_Test1_[ b'label']==1][b'weight']\n",
        "DataSet_Test1_weight_SM = DataSet_Test1_[DataSet_Test1_[ b'label']==2][b'weight']\n",
        "DataSet_Test1_weight = DataSet_Test1_[b'weight']\n",
        "\n",
        "\n",
        "DataSet_Test8_weight_backg = DataSet_Test8_[DataSet_Test8_[ b'label']==0][b'weight']\n",
        "DataSet_Test8_weight_signal = DataSet_Test8_[DataSet_Test8_[ b'label']==1][b'weight']\n",
        "DataSet_Test8_weight_SM = DataSet_Test8_[DataSet_Test8_[ b'label']==2][b'weight']\n",
        "DataSet_Test8_weight = DataSet_Test8_[b'weight']\n",
        "\n",
        "\n",
        "DataSet_Test7_weight_backg = DataSet_Test7_[DataSet_Test7_[ b'label']==0][b'weight']\n",
        "DataSet_Test7_weight_signal = DataSet_Test7_[DataSet_Test7_[ b'label']==1][b'weight']\n",
        "DataSet_Test7_weight_SM = DataSet_Test7_[DataSet_Test7_[ b'label']==2][b'weight']\n",
        "DataSet_Test7_weight = DataSet_Test7_[b'weight']\n",
        "\n",
        "\n",
        "DataSet_Test6_weight_backg = DataSet_Test6_[DataSet_Test6_[ b'label']==0][b'weight']\n",
        "DataSet_Test6_weight_signal = DataSet_Test6_[DataSet_Test6_[ b'label']==1][b'weight']\n",
        "DataSet_Test6_weight_SM = DataSet_Test6_[DataSet_Test6_[ b'label']==2][b'weight']\n",
        "DataSet_Test6_weight = DataSet_Test6_[b'weight']\n",
        "\n",
        "\n",
        "DataSet_Test5_weight_backg = DataSet_Test5_[DataSet_Test5_[ b'label']==0][b'weight']\n",
        "DataSet_Test5_weight_signal = DataSet_Test5_[DataSet_Test5_[ b'label']==1][b'weight']\n",
        "DataSet_Test5_weight_SM = DataSet_Test5_[DataSet_Test5_[ b'label']==2][b'weight']\n",
        "DataSet_Test5_weight = DataSet_Test5_[b'weight']\n",
        "\n",
        "\n",
        "DataSet_Test2_weight_backg = DataSet_Test2_[DataSet_Test2_[ b'label']==0][b'weight']\n",
        "DataSet_Test2_weight_signal = DataSet_Test2_[DataSet_Test2_[ b'label']==1][b'weight']\n",
        "DataSet_Test2_weight_SM = DataSet_Test2_[DataSet_Test2_[ b'label']==2][b'weight']\n",
        "DataSet_Test2_weight = DataSet_Test2_[b'weight']\n",
        "\n",
        "\n",
        "DataSet_Test3_weight_backg = DataSet_Test3_[DataSet_Test3_[ b'label']==0][b'weight']\n",
        "DataSet_Test3_weight_signal = DataSet_Test3_[DataSet_Test3_[ b'label']==1][b'weight']\n",
        "DataSet_Test3_weight_SM = DataSet_Test3_[DataSet_Test3_[ b'label']==2][b'weight']\n",
        "DataSet_Test3_weight = DataSet_Test3_[b'weight']\n",
        "\n",
        "\n",
        "DataSet_Test4_weight_backg = DataSet_Test4_[DataSet_Test4_[ b'label']==0][b'weight']\n",
        "DataSet_Test4_weight_signal = DataSet_Test4_[DataSet_Test4_[ b'label']==1][b'weight']\n",
        "DataSet_Test4_weight_SM = DataSet_Test4_[DataSet_Test4_[ b'label']==2][b'weight']\n",
        "DataSet_Test4_weight = DataSet_Test4_[b'weight']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObGlcf9U8D0A"
      },
      "source": [
        "# Abrindo arquivos já treinados - Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R-0MMj_duKN"
      },
      "outputs": [],
      "source": [
        "search_result1_Multiclass_logloss_scale_pos_weight = load(PATH2 + 'VotingClassifier_Soft_Multiclass_ANOMALO1_DataDriven.joblib')\n",
        "search_result2_Multiclass_logloss_scale_pos_weight = load(PATH2 + 'VotingClassifier_Soft_Multiclass_ANOMALO2_DataDriven.joblib')\n",
        "search_result3_Multiclass_logloss_scale_pos_weight = load(PATH2 + 'VotingClassifier_Soft_Multiclass_ANOMALO3_DataDriven.joblib')\n",
        "search_result4_Multiclass_logloss_scale_pos_weight = load(PATH2 + 'VotingClassifier_Soft_Multiclass_ANOMALO4_DataDriven.joblib')\n",
        "search_result5_Multiclass_logloss_scale_pos_weight = load(PATH  + 'VotingClassifier_Soft_Multiclass_ANOMALO5**_DataDriven.joblib')\n",
        "search_result6_Multiclass_logloss_scale_pos_weight = load(PATH2 + 'VotingClassifier_Soft_Multiclass_ANOMALO6_DataDriven.joblib')\n",
        "search_result7_Multiclass_logloss_scale_pos_weight = load(PATH2 + 'VotingClassifier_Soft_Multiclass_ANOMALO7_DataDriven.joblib')\n",
        "search_result8_Multiclass_logloss_scale_pos_weight = load(PATH2 + 'VotingClassifier_Soft_Multiclass_ANOMALO8_DataDriven.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c42UUcCz9mfp"
      },
      "source": [
        "# Distribuição de Probabilidade\n",
        "- Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FKHllhkfbES"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer,fbeta_score,precision_score,recall_score,accuracy_score,log_loss,roc_auc_score,classification_report,f1_score,confusion_matrix,roc_curve,precision_recall_curve,average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8EQdEN9d4dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de64bb8c-581e-416b-9ac5-5bf607f7491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "predict1_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result1_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test1)\n",
        "predict2_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result2_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test2)\n",
        "predict3_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result3_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test3)\n",
        "predict4_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result4_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test4)\n",
        "predict5_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result5_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test5)\n",
        "predict6_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result6_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test6)\n",
        "predict7_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result7_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test7)\n",
        "predict8_VotingClassifier_multiclass_logloss_scale_pos_weight = search_result8_Multiclass_logloss_scale_pos_weight.predict(DataSet_Test8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGt0fJfN23XJ"
      },
      "source": [
        "# Contagem do número de eventos após o corte\n",
        "- Usando o valor default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvdWkJbkDYwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ca9f87-ec60-4de1-d4ea-7872820b5f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['bytes']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "predict_dados1 = search_result1_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])\n",
        "predict_dados2 = search_result2_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])\n",
        "predict_dados3 = search_result3_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])\n",
        "predict_dados4 = search_result4_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])\n",
        "predict_dados5 = search_result5_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])\n",
        "predict_dados6 = search_result6_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])\n",
        "predict_dados7 = search_result7_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])\n",
        "predict_dados8 = search_result8_Multiclass_logloss_scale_pos_weight.predict_proba(data_set_dados_multirp[colunas])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU8M-cRsMdCf"
      },
      "source": [
        "# Usando o valor de corte como 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJKwpTj1CpTR"
      },
      "outputs": [],
      "source": [
        "best_cut = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crbcqUnVFTc_"
      },
      "outputs": [],
      "source": [
        "n_eventos_backg_dps_corte1 = predict1_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML1 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte1 = predict1_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML1 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte1 = predict1_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML1 == 2 ] > best_cut\n",
        "\n",
        "\n",
        "n_eventos_backg_dps_corte2 = predict2_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML2 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte2 = predict2_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML2 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte2 = predict2_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML2 == 2 ] > best_cut\n",
        "\n",
        "\n",
        "n_eventos_backg_dps_corte3 = predict3_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML3 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte3 = predict3_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML3 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte3 = predict3_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML3 == 2 ] > best_cut\n",
        "\n",
        "\n",
        "n_eventos_backg_dps_corte4 = predict4_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML4 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte4 = predict4_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML4 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte4 = predict4_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML4 == 2 ] > best_cut\n",
        "\n",
        "\n",
        "n_eventos_backg_dps_corte5 = predict5_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML5 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte5 = predict5_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML5 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte5 = predict5_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML5 == 2 ] > best_cut\n",
        "\n",
        "\n",
        "n_eventos_backg_dps_corte6 = predict6_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML6 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte6 = predict6_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML6 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte6 = predict6_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML6 == 2 ] > best_cut\n",
        "\n",
        "\n",
        "n_eventos_backg_dps_corte7 = predict7_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML7 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte7 = predict7_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML7 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte7 = predict7_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML7 == 2 ] > best_cut\n",
        "\n",
        "\n",
        "n_eventos_backg_dps_corte8 = predict8_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML8 == 0 ] > best_cut\n",
        "n_eventos_signal_dps_corte8 = predict8_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML8 == 1 ] > best_cut\n",
        "n_eventos_SM_dps_corte8 = predict8_VotingClassifier_multiclass_logloss_scale_pos_weight[ label_test_ANML8 == 2 ] > best_cut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9x232b9Ggis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad22c8b9-8967-40f2-cfba-d9ec5d408e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO1------------------\n",
            "Numero de eventos de background depois do corte --> 0.016949344637419136\n",
            "Numero de eventos de signal depois do corte --> 4.208744505872212\n",
            "Numero de eventos de SM depois do corte --> 0.05331533855542411\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO1------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test1_weight_backg [ n_eventos_backg_dps_corte1 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test1_weight_signal[ n_eventos_signal_dps_corte1].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test1_weight_SM [ n_eventos_SM_dps_corte1 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvsoU3azLr4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0560eb58-2a9e-4cbb-b54a-64e32d051aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO2------------------\n",
            "Numero de eventos de background depois do corte --> 0.0\n",
            "Numero de eventos de signal depois do corte --> 0.07462531226336878\n",
            "Numero de eventos de SM depois do corte --> 0.03576116965987043\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO2------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test2_weight_backg [ n_eventos_backg_dps_corte2 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test2_weight_signal[ n_eventos_signal_dps_corte2].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test2_weight_SM [ n_eventos_SM_dps_corte2 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPtjgbJGEZkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f55a65-de17-4782-a870-132d6ffbb5d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO3------------------\n",
            "Numero de eventos de background depois do corte --> 0.0016062964667151066\n",
            "Numero de eventos de signal depois do corte --> 0.3031722830074729\n",
            "Numero de eventos de SM depois do corte --> 0.04934104386148424\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO3------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test3_weight_backg [ n_eventos_backg_dps_corte3 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test3_weight_signal[ n_eventos_signal_dps_corte3].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test3_weight_SM [ n_eventos_SM_dps_corte3 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWbHMa66Ev-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa1b535-fdd8-42d7-928f-c45a4bf90cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO4------------------\n",
            "Numero de eventos de background depois do corte --> 0.0016062964667151066\n",
            "Numero de eventos de signal depois do corte --> 0.7431258560669411\n",
            "Numero de eventos de SM depois do corte --> 0.053414893299615\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO4------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test4_weight_backg [ n_eventos_backg_dps_corte4 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test4_weight_signal[ n_eventos_signal_dps_corte4].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test4_weight_SM [ n_eventos_SM_dps_corte4 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkLZBG2QE4Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814f8043-3447-4065-a3cc-aee46a1d2040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO5------------------\n",
            "Numero de eventos de background depois do corte --> 0.0\n",
            "Numero de eventos de signal depois do corte --> 0.055567128785089\n",
            "Numero de eventos de SM depois do corte --> 0.03774942734183731\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO5------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test5_weight_backg [ n_eventos_backg_dps_corte5 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test5_weight_signal[ n_eventos_signal_dps_corte5].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test5_weight_SM [ n_eventos_SM_dps_corte5 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01D5fchgE9tD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af043df-ffc2-4389-a03e-ad0a1db0e7df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO6------------------\n",
            "Numero de eventos de background depois do corte --> 0.0\n",
            "Numero de eventos de signal depois do corte --> 0.194677178865226\n",
            "Numero de eventos de SM depois do corte --> 0.04122099889378006\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO6------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test6_weight_backg [ n_eventos_backg_dps_corte6 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test6_weight_signal[ n_eventos_signal_dps_corte6].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test6_weight_SM [ n_eventos_SM_dps_corte6 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG0pDEOZFFhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c192c650-4627-4361-fffd-76404a6d5c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO7------------------\n",
            "Numero de eventos de background depois do corte --> 0.010346905096279333\n",
            "Numero de eventos de signal depois do corte --> 0.6432567381363425\n",
            "Numero de eventos de SM depois do corte --> 0.04814450095894211\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO7------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test7_weight_backg [ n_eventos_backg_dps_corte7 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test7_weight_signal[ n_eventos_signal_dps_corte7].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test7_weight_SM [ n_eventos_SM_dps_corte7 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C_QGMkpFLU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26925c27-98e1-45b1-cc9e-5d1c584d1e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO8------------------\n",
            "Numero de eventos de background depois do corte --> 0.042268173558140214\n",
            "Numero de eventos de signal depois do corte --> 4.241444655801601\n",
            "Numero de eventos de SM depois do corte --> 0.051546422434979276\n"
          ]
        }
      ],
      "source": [
        "print('------------------ANOMALO8------------------')\n",
        "print('Numero de eventos de background depois do corte -->', DataSet_Test8_weight_backg [ n_eventos_backg_dps_corte8 ].sum() / test_size_ )\n",
        "print('Numero de eventos de signal depois do corte -->', DataSet_Test8_weight_signal[ n_eventos_signal_dps_corte8].sum() / test_size_ )\n",
        "print('Numero de eventos de SM depois do corte -->', DataSet_Test8_weight_SM [ n_eventos_SM_dps_corte8 ].sum() / test_size_ )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DegKtjrlQz4"
      },
      "source": [
        "# Erro associado a contagem de eventos\n",
        "\n",
        "$\\sigma = \\sqrt{\\sum_{i = 1}^{n} w_{i}^2}$\n",
        "\n",
        "Somente para os anomalos 1 e 8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt"
      ],
      "metadata": {
        "id": "LdjAuFsgBVDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def erro_calculate(erro_topologia):\n",
        "  passo1 = erro_topologia**2\n",
        "  passo2 = passo1.sum()\n",
        "  passo3 = sqrt(passo2)\n",
        "  return passo3"
      ],
      "metadata": {
        "id": "fGCenhYsBxva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "erro1_signal = DataSet_Test1_weight_signal[ n_eventos_signal_dps_corte1] / test_size_\n",
        "erro1_backg = DataSet_Test1_weight_backg[n_eventos_backg_dps_corte1] / test_size_\n",
        "erro1_SM = DataSet_Test1_weight_SM[n_eventos_SM_dps_corte1] / test_size_\n",
        "\n",
        "\n",
        "erro8_signal = DataSet_Test8_weight_signal[n_eventos_signal_dps_corte8] / test_size_\n",
        "erro8_backg = DataSet_Test8_weight_backg[n_eventos_backg_dps_corte8] / test_size_\n",
        "erro8_SM = DataSet_Test8_weight_SM [ n_eventos_SM_dps_corte8 ].sum() / test_size_"
      ],
      "metadata": {
        "id": "nO9bc_Us_Bf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('------------------ANOMALO1------------------')\n",
        "print('\\n')\n",
        "print(f'Erro na região de Sinal do ANOMALO 1 --> {erro_calculate(erro1_signal)}')\n",
        "print(f'Erro na região de Background do ANOMALO 1 -->  {erro_calculate(erro1_backg)}')\n",
        "print(f'Erro na região do Modelo Padrão do ANOMALO 1 --> {erro_calculate(erro1_SM)}')\n",
        "print('\\n')\n",
        "print('------------------ANOMALO8------------------')\n",
        "print('\\n')\n",
        "print(f'Erro na região de Sinal do ANOMALO 8 --> {erro_calculate(erro8_signal)}')\n",
        "print(f'Erro na região de Background do ANOMALO 8 --> {erro_calculate(erro8_backg)}')\n",
        "print(f'Erro na região do Modelo Padrão do ANOMALO 8 --> {erro_calculate(erro8_SM)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwovzxA7CFhj",
        "outputId": "9af6404e-b80d-4295-fa27-641ca19c4456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ANOMALO1------------------\n",
            "\n",
            "\n",
            "Erro na região de Sinal do ANOMALO 1 --> 0.18410608953839322\n",
            "Erro na região de Background do ANOMALO 1 -->  0.008840795958736904\n",
            "Erro na região do Modelo Padrão do ANOMALO 1 --> 0.009975292403642\n",
            "\n",
            "\n",
            "------------------ANOMALO8------------------\n",
            "\n",
            "\n",
            "Erro na região de Sinal do ANOMALO 8 --> 0.1831080113395698\n",
            "Erro na região de Background do ANOMALO 8 --> 0.01856896922290986\n",
            "Erro na região do Modelo Padrão do ANOMALO 8 --> 0.051546422434979276\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tH3jahOi7A7A",
        "JA-FOF2j70O4",
        "ObGlcf9U8D0A"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}